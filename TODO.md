# AIBackgroundWorker プロジェクト進捗状況

最終更新: 2025-11-28 (進捗分析反映)

## 📋 プロジェクト概要

AIシステムを動かすための背景として動作する常駐システム。ユーザーの活動データと外部情報を自動的に収集・蓄積し、AIシステムが活用できる形でデータを提供します。

**技術スタック**: SQLite (WALモード) + Python 3.12 + uv

---

## ✅ 完了済みタスク

### プロジェクト構造の整理
- [x] 不要ファイル（Zone.Identifier、uv.lock、.pidファイル）の削除
- [x] スクリプトの統合（browser、info_collector、lifelog → scripts/）
- [x] パッケージ管理をuvに統一
- [x] プロジェクト構造の整理とドキュメント化
- [x] CLAUDE.mdの作成

### ライフログシステム（lifelog-system）
- [x] 基本的なプロジェクト構造の確立
- [x] SQLiteデータベース構造の実装（lifelog.db）
- [x] デーモン制御スクリプト（scripts/daemon.sh）
- [x] CLIビューアー（日別サマリー、タイムライン、時間帯別活動）
- [x] Windows前面ウィンドウロガー統合
- [x] プライバシー保護機能（ハッシュ化）

### ブラウザ履歴システム
- [x] データモデルの実装（BrowserHistoryEntry）
- [x] リポジトリの実装（BrowserHistoryRepository）
- [x] SQLiteスキーマの実装（ai_secretary.db）
- [x] インポートスクリプト（import_brave_history.sh）
- [x] 定期ポーリングスクリプト（poll_brave_history.sh）
- [x] cron登録スクリプト（install_poll_cron.sh）

### 外部情報収集システム（info_collector）
- [x] 基本的なプロジェクト構造の確立（src/info_collector/）
- [x] SQLiteデータベース構造の実装（repository.py: 299行）
- [x] データモデルの実装（models.py: 74行）
- [x] 設定管理の実装（config.py: 46行）
- [x] ニュース収集機能（collectors/news_collector.py: 164行）
- [x] RSS収集機能（collectors/rss_collector.py: 89行）
- [x] Web検索機能（collectors/search_collector.py: 54行）
- [x] DuckDuckGo検索クライアント（search/ddg_client.py: 85行）
- [x] 検索クエリプランナー（search_planner.py: 160行、Ollama統合）
- [x] 記事要約機能（summarizer.py: 232行）
- [x] Deep-dive分析パイプライン（jobs/analyze_pending.py: 106行）
- [x] 深掘りリサーチ機能（jobs/deep_research.py: 133行）
- [x] レポート生成機能（jobs/generate_report.py: 83行）
- [x] プロンプト管理システム（prompts/: 4ファイル、255行）
- [x] 自動実行スクリプト（auto_collect.sh等4つのスクリプト）
- [x] systemd定期実行設定（4つのタイマー: collector/analyze/deep/report）
- [x] ユニットテスト・統合テスト（391行のテストコード）

---

## 🚧 進行中タスク

### CLIビューアーの拡張
- [ ] info_collectorデータの表示機能（ニュース、RSS、検索結果、レポート）
- [ ] ブラウザ履歴表示機能
- [ ] ブラウザ履歴とライフログの相関表示

### ブラウザ履歴機能の完成
- [ ] `src.browser_history.BraveHistoryImporter` の実装確認・完成 🚧

### ライフログシステムの機能拡張
- [ ] データ収集の精度向上
- [ ] エラーハンドリングの強化
- [ ] ログローテーション機能

---

## 📝 未実装・計画中タスク

### 内向きの機能（Internal Data Collection）

#### ユーザー活動のデータ収集
- [x] WSL環境での活動記録の完全実装 ✅
  - [x] プロセス情報の収集
  - [x] アクティブウィンドウ情報の取得
  - [x] アプリケーション使用状況の記録
- [x] Windows環境での活動記録の完全実装 ✅
  - [x] フォアグラウンドウィンドウの記録
  - [x] アクティビティタイムラインの生成
- [x] WSLとWindowsデータの統合機能 ✅
  - [x] データマージ機能（merge_windows_logs.py）
  - [x] 時系列データの統合
- [ ] タスクスケジューラでの自動実行設定
  - [x] Windows前面ウィンドウロガーの自動起動設定方法 ✅
  - [x] WSL側デーモンの自動起動設定方法 ✅
  - [x] データ統合処理の定期実行設定方法 ✅

#### ブラウザ情報の自動取得
- [ ] ブラウザ履歴の可視化機能
  - [ ] 日別アクセス統計
  - [ ] ドメイン別集計
  - [ ] タイムライン表示
- [ ] 他のブラウザ対応（Chrome、Firefox等）
- [ ] ブラウザとライフログの統合ビュー

### 外向きの機能（External Data Collection）

#### ニュース収集（SQLiteベース）
- [x] ニュース収集機能の実装 ✅
  - [x] `src.info_collector` パッケージ構造の作成
  - [x] `src.info_collector.NewsCollector` の実装
  - [x] 複数ニュースサイトからの収集
  - [x] SQLiteテーブル設計（news_articles）
- [x] ニュース収集の定期実行機能 ✅
- [x] ニュースの重複排除機能 ✅

#### RSSフィード収集（SQLiteベース）
- [x] RSS収集機能の実装 ✅
  - [x] `src.info_collector.RSSCollector` の実装
  - [x] feedparserライブラリの統合
  - [x] 複数RSSフィードからの収集
  - [x] SQLiteテーブル設計（rss_entries）
- [x] RSS収集の定期実行機能 ✅

#### Web検索機能（SQLiteベース）
- [x] Web検索機能の実装 ✅
  - [x] `src.info_collector.SearchCollector` の実装
  - [x] DuckDuckGo等の検索API統合
  - [x] SQLiteテーブル設計（search_results）
- [x] 検索結果の要約生成機能 ✅
- [x] Deep-dive分析・深掘りリサーチ機能 ✅
- [x] レポート生成パイプライン ✅

#### 情報管理
- [x] `src.info_collector.InfoCollectorRepository` の実装 ✅
- [x] `src.info_collector.InfoCollectorConfig` の実装 ✅
- [x] 情報の重複排除と更新管理 ✅

### データ可視化機能

#### CLIツールの拡張
- [ ] データ閲覧機能の拡張
  - [ ] ブラウザ履歴の表示
  - [ ] 外部情報の表示（info_collector）
  - [ ] 検索結果の表示
  - [ ] レポートの表示
  - [ ] データ統計の表示
- [ ] エクスポート機能（CSV、JSON等）
- [ ] 統合ダッシュボード（全データの概要）

### システム統合

#### MCP Server実装
- [ ] MCP Serverの設計
- [ ] Claude連携機能の実装
- [ ] データ取得APIの実装
- [ ] セマンティック検索インターフェース

#### Windows API実装
- [ ] Win32 APIの統合
- [ ] Windows固有機能の実装

### その他の機能

#### パフォーマンス最適化
- [ ] データ収集の効率化
- [ ] データベースクエリの最適化
- [ ] メモリ使用量の最適化

#### テストと品質保証
- [ ] ユニットテストの拡充
- [ ] 統合テストの実装
- [ ] エンドツーエンドテストの実装
- [ ] コードカバレッジの向上

#### ドキュメント
- [ ] APIドキュメントの作成
- [ ] 開発者ガイドの作成
- [ ] 運用マニュアルの作成

---

## 🔮 将来検討タスク（現時点では不要）

### ベクターDB統合（必要になったら実装）
**判断基準**: AIエージェントが実際に使い始めて、セマンティック検索が必要になったら

- [ ] ベクターDBの選定とセットアップ
  - [ ] ChromaDB / Qdrant / Pinecone等の検討
- [ ] データのベクター化処理
  - [ ] テキスト埋め込みの生成
  - [ ] メタデータの付与
- [ ] ベクターDBへの保存機能
- [ ] セマンティック検索機能の実装

**必要になるケース**:
- ニュース記事の全文を保存し始めた時
- 「○○について最近何か情報ある？」のような自然言語クエリが必要な時
- 類似度検索が必要になった時

### Web UI（将来の拡張）
- [ ] Web UIの設計
- [ ] フロントエンドフレームワークの選定
- [ ] バックエンドAPIの実装
- [ ] データ可視化ダッシュボード

### ローカルLLM統合
- [ ] ローカルLLMの選定とセットアップ
- [ ] 日次サマリー生成機能
- [ ] データ分析機能

---

## 🎯 現実的な優先度別タスク

### 【高優先度】今すぐ実装すべき

1. **ブラウザ履歴機能の完成** ⭐
   - `src.browser_history.BraveHistoryImporter` の実装確認
   - CLIビューアーでの表示機能追加
   - 理由: リポジトリは実装済み、残りわずかで完成

2. **外部情報収集機能の実装（SQLiteベース）** ⭐
   - `src.info_collector` パッケージ構造の作成
   - ニュース収集機能の実装
   - RSS収集機能の実装
   - 理由: プロジェクトの主要機能の1つ

3. **データ統合・可視化の強化**
   - 全データを統合したCLIダッシュボード
   - ブラウザ履歴とライフログの相関表示
   - 理由: データが増えてきたので統合ビューが必要

### 【中優先度】次に実装すべき

1. **MCP Server実装**
   - Claude連携によるAIシステムとの統合
   - データ取得APIの実装
   - 理由: AIシステムとの連携が目的

2. **定期実行機能の実装**
   - ニュース、RSS、ブラウザ履歴の自動収集
   - cron/タスクスケジューラ設定の自動化
   - 理由: 手動実行は現実的でない

3. **テストの拡充**
   - ユニットテスト
   - 統合テスト
   - 理由: 品質保証

### 【低優先度】余裕があれば

1. **他のブラウザ対応**
2. **Windows API実装（Win32）**
3. **パフォーマンス最適化**

---

## 📊 進捗率

- **プロジェクト構造**: 100% ✅
- **ライフログシステム（基本機能）**: 85% 🚧
- **ブラウザ情報収集（基盤）**: 70% 🚧
- **ブラウザ情報収集（完成）**: 30% 🚧
- **外部情報収集（基本機能）**: 90% ✅
  - ニュース収集: 100% ✅
  - RSS収集: 100% ✅
  - Web検索: 100% ✅
  - Deep-dive分析: 100% ✅
  - レポート生成: 100% ✅
  - 定期実行: 100% ✅
  - テスト: 80% 🚧
- **データ可視化（CLIツール）**: 45% 🚧
- **MCP Server**: 0% 📝

**全体進捗**: 約 65%（外部情報収集機能の実装完了により大幅上昇）

---

## 🚀 次の具体的アクション（優先順位順）

### 1. CLIビューアーでのinfo_collector表示機能（1-2日）⭐
```bash
# lifelog-system/src/lifelog/cli_viewer.py に追加
# - info_collector データの表示コマンド
#   - ニュース一覧表示
#   - RSS一覧表示
#   - 検索結果表示
#   - レポート表示
#   - 統計サマリー
```

### 2. ブラウザ履歴機能の完成（1-2日）
```bash
# 実装状況の確認
cd lifelog-system
ls -la src/browser_history/

# 必要な実装
# - BraveHistoryImporter の完成
# - CLIビューアーでの表示機能
```

### 3. データ統合ビューの実装（1-2日）
```bash
# 統合ダッシュボードの実装
# - ライフログ + ブラウザ履歴 + info_collector の統合表示
# - 時系列での相関表示
# - 日次サマリーの拡張
```

---

## 🔄 定期的な更新

このTODOリストは定期的に更新してください。タスクの完了時、新しい要件の追加時、優先度の変更時に更新します。

---

## 📝 メモ

### 技術的な決定事項
- **データベース**: SQLiteを採用（WALモード最適化済み）
  - lifelog.db: ライフログデータ
  - ai_secretary.db: ブラウザ履歴＋外部情報（予定）
- **ベクターDB**: 現時点では不要、将来必要になったら検討
  - 理由: 現在のデータは全て構造化データで、SQLiteで十分検索可能
  - 必要になるタイミング: セマンティック検索、全文検索が必要になった時

### 現状
- プロジェクト構造の整理が完了し、基本的なライフログシステムの骨格は実装済み
- ブラウザ履歴の基盤（モデル、リポジトリ、スクリプト）は実装済み
- 次は「完成」と「外部情報収集」にフォーカス

### 設計方針
- YAGNI原則（You Aren't Gonna Need It）: 必要になるまで実装しない
- まずSQLiteで完成させる → 実際に使ってみる → 必要なら拡張
